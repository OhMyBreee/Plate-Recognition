{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8134d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/bryan_santosa/miniconda3/envs/machinelearning/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting albumentations\n",
      "  Using cached albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: PyYAML in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from albumentations) (2.11.9)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from albumentations) (4.12.0)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-4.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (110 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Using cached simsimd-6.5.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (70 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Using cached albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Using cached simsimd-6.5.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "Downloading stringzilla-4.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (592 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m592.2/592.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: simsimd, stringzilla, albucore, albumentations\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/4\u001b[0m [albumentations]m [albumentations]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed albucore-0.0.24 albumentations-2.0.8 simsimd-6.5.3 stringzilla-4.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7438ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch # If you use PyTorch later for training\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Choose an integer seed (e.g., 42, 0, or any number)\n",
    "SEED = 42\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    # If you use PyTorch, uncomment these:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8793253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: test\n",
      "Processing directory: train\n",
      "Processing directory: val\n",
      "‚úÖ Data augmentation complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from glob import glob\n",
    "\n",
    "# Paths\n",
    "INPUT_DATA_ROOT = \"../data/raw/Indonesian License Plate Dataset/\"\n",
    "\n",
    "input_images = os.path.join(INPUT_DATA_ROOT, \"images\")\n",
    "input_labels = os.path.join(INPUT_DATA_ROOT, \"labels\")\n",
    "\n",
    "# OUTPUT Paths (A new folder to store the augmented data, usually outside of 'raw')\n",
    "OUTPUT_DATA_ROOT = \"../data/processed/\"\n",
    "\n",
    "output_images = os.path.join(OUTPUT_DATA_ROOT, \"images\")\n",
    "output_labels = os.path.join(OUTPUT_DATA_ROOT, \"labels\")\n",
    "\n",
    "# --- END: Updated Paths ---\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(output_images, exist_ok=True)\n",
    "os.makedirs(output_labels, exist_ok=True)\n",
    "\n",
    "# Define augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.MotionBlur(blur_limit=5, p=0.3),\n",
    "    A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "],\n",
    "bbox_params=A.BboxParams(\n",
    "    format='yolo', \n",
    "    label_fields=['class_labels'],\n",
    "    # Add clip=True to ensure all coordinates are strictly within [0.0, 1.0]\n",
    "    clip=True,\n",
    "    min_area=1.0\n",
    "))\n",
    "\n",
    "# Loop through all images\n",
    "for subdir in os.listdir(input_images):\n",
    "    # Construct the full paths for the current subdirectory\n",
    "    current_input_image_dir = os.path.join(input_images, subdir)\n",
    "    current_input_label_dir = os.path.join(input_labels, subdir)\n",
    "\n",
    "    # üõë FIX 2: Create the corresponding output subdirectories\n",
    "    current_output_image_dir = os.path.join(output_images, subdir)\n",
    "    current_output_label_dir = os.path.join(output_labels, subdir)\n",
    "\n",
    "    os.makedirs(current_output_image_dir, exist_ok=True)\n",
    "    os.makedirs(current_output_label_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing directory: {subdir}\")\n",
    "\n",
    "    # Loop through all images in the subdirectory\n",
    "    # Using os.path.join is safer than f-string concatenation for paths\n",
    "    for img_path in glob(os.path.join(current_input_image_dir, \"*.jpg\")):\n",
    "        filename = os.path.basename(img_path)\n",
    "        \n",
    "        # üõë FIX 1: Correctly construct the label path using the subdirectory path\n",
    "        label_path = os.path.join(current_input_label_dir, filename.replace(\".jpg\", \".txt\"))\n",
    "\n",
    "        # Safety Check: Ensure the label file exists before proceeding\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Label file not found for {filename} in {subdir}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Read image and labels (continue with your original logic)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not read image {img_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        h, w, _ = image.shape # This is for context, not strictly needed by the augmentation code\n",
    "\n",
    "        # ... (rest of the label reading, augmentation, and saving logic) ...\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            labels = f.readlines()\n",
    "\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        for label in labels:\n",
    "            try:\n",
    "                cls, x, y, bw, bh = map(float, label.strip().split())\n",
    "                bboxes.append([x, y, bw, bh])\n",
    "                class_labels.append(int(cls))\n",
    "            except Exception as e:\n",
    "                 # Added error handling for malformed lines\n",
    "                print(f\"Error processing label line in {label_path}: {e}. Skipping image.\")\n",
    "                continue\n",
    "\n",
    "        # Apply transformation\n",
    "        transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "\n",
    "        aug_img = transformed['image']\n",
    "        aug_bboxes = transformed['bboxes']\n",
    "        aug_labels = transformed['class_labels']\n",
    "\n",
    "        # üõë FIX 2 (Final Save): Save augmented files into the correct OUTPUT subdirectory\n",
    "        \n",
    "        # Adding 'aug_' prefix is good practice to distinguish augmented files\n",
    "        aug_filename = f\"aug_{filename}\" \n",
    "\n",
    "        # Save augmented image\n",
    "        save_path_img = os.path.join(current_output_image_dir, aug_filename)\n",
    "        cv2.imwrite(save_path_img, aug_img)\n",
    "\n",
    "        # Save updated YOLO labels\n",
    "        save_path_lbl = os.path.join(current_output_label_dir, aug_filename.replace(\".jpg\", \".txt\"))\n",
    "        with open(save_path_lbl, \"w\") as f:\n",
    "            for cls, bbox in zip(aug_labels, aug_bboxes):\n",
    "                f.write(f\"{cls} {' '.join(map(str, bbox))}\\n\")\n",
    "\n",
    "print(\"‚úÖ Data augmentation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608491d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO version: 1\n",
      "CUDA available: True\n",
      "Device being used: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"YOLO version:\", YOLO._version)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device being used:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e9589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Returns the number of CUDA devices detected (e.g., 1, 2, 4)\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac8d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        # Prints the index and the GPU model name\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your PyTorch installation and NVIDIA drivers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1806326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Total VRAM: 5.99951171875 GB\n",
      "Allocated VRAM: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the name of the currently selected device\n",
    "print(\"Current Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# Check total and allocated memory on the current GPU (useful for debugging OOM errors)\n",
    "print(\"Total VRAM:\", torch.cuda.get_device_properties(0).total_memory / 1024**3, \"GB\")\n",
    "print(\"Allocated VRAM:\", torch.cuda.memory_allocated(0) / 1024**3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8d23445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "YOLO target device: cuda\n",
      "‚úÖ Model device (PyTorch check): cuda:0\n",
      "Starting YOLOv8 training...\n",
      "Ultralytics 8.3.222 üöÄ Python-3.10.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=lp_detection_fine_tune_v2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 1.5¬±0.2 ms, read: 222.7¬±23.9 MB/s, size: 2023.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/data/processed/labels/train.cache... 800 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 800/800 1.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 2.2¬±0.4 ms, read: 132.2¬±12.3 MB/s, size: 1821.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/data/processed/labels/val.cache... 100 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100/100 33.0Kit/s 0.0s\n",
      "Plotting labels to /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000515625), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/40      1.64G      1.585      3.049      1.159         19        640: 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 98/134 7.1it/s 19.3s<5.1ss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/bryan_santosa/miniconda3/envs/machinelearning/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/40      1.64G      1.554      2.802      1.157          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 4.9it/s 27.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 7.8it/s 1.2s0.1s\n",
      "                   all        100        179      0.874      0.726      0.838      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/40      1.72G      1.495      1.758      1.136          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.7it/s 17.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.5it/s 0.9s0.1s\n",
      "                   all        100        179      0.754      0.799      0.858      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/40      1.72G       1.48      1.602       1.13          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.4it/s 18.2s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.4it/s 1.1s0.1s\n",
      "                   all        100        179      0.642      0.793      0.623      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/40      1.74G      1.476      1.289      1.114          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 9.2it/s 14.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 10.0it/s 0.9s.1s\n",
      "                   all        100        179      0.927      0.852      0.935      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/40      1.75G      1.432      1.176      1.097          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.3it/s 18.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.5it/s 1.1s0.1s\n",
      "                   all        100        179      0.917      0.844      0.935      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/40      1.76G      1.413      1.142      1.113          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.6it/s 15.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 10.5it/s 0.9s.1s\n",
      "                   all        100        179      0.811      0.883        0.9      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/40      1.79G      1.391      1.071        1.1          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.4it/s 18.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.2it/s 1.0s0.1s\n",
      "                   all        100        179      0.905      0.916      0.951      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/40       1.8G      1.359     0.9539      1.076          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.9it/s 15.0s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.6it/s 0.9s0.1s\n",
      "                   all        100        179      0.915      0.944      0.972      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/40      1.82G       1.31     0.9086      1.052          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.3it/s 18.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.7it/s 1.0s0.1s\n",
      "                   all        100        179      0.944      0.922       0.97      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/40      1.84G       1.32     0.9031      1.059          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.7it/s 15.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.4it/s 1.0s0.1s\n",
      "                   all        100        179      0.927      0.923      0.966      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/40      1.85G      1.257     0.8632      1.037          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.8it/s 19.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.6it/s 1.0s0.1s\n",
      "                   all        100        179       0.95      0.877      0.965        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/40      1.87G      1.273     0.8305      1.038          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.4it/s 15.9s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 7.6it/s 1.2s0.2s\n",
      "                   all        100        179      0.879      0.955      0.966       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/40      1.89G      1.264     0.8361      1.032          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.5it/s 15.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.1it/s 1.0s0.1s\n",
      "                   all        100        179      0.927      0.923       0.97      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/40      1.91G       1.27     0.8361      1.032         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.4it/s 18.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 10.1it/s 0.9s.1s\n",
      "                   all        100        179       0.96      0.928      0.978      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/40      1.92G      1.247     0.8113      1.023          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.2it/s 16.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.1it/s 1.1s0.1s\n",
      "                   all        100        179      0.932      0.916      0.973      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/40      1.92G      1.233     0.7745      1.023          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.0it/s 19.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 10.2it/s 0.9s.1s\n",
      "                   all        100        179      0.933       0.95      0.975      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/40      1.92G      1.255     0.7925      1.022          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.2it/s 16.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.2it/s 1.1s0.1s\n",
      "                   all        100        179      0.925       0.96      0.979      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/40      1.92G      1.207     0.7757      1.005          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.7it/s 20.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.0it/s 1.0s0.1s\n",
      "                   all        100        179      0.933       0.94      0.964      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/40      1.92G      1.225     0.7816      1.029          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.5it/s 15.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.8it/s 0.9s0.1s\n",
      "                   all        100        179       0.97      0.902      0.968      0.671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/40      1.92G      1.195     0.7483      1.001          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.0it/s 19.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.5it/s 1.1s0.1s\n",
      "                   all        100        179       0.96      0.927      0.982      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/40      1.92G      1.186     0.7242     0.9964          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.3it/s 16.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.9it/s 1.0s0.1s\n",
      "                   all        100        179      0.955      0.952      0.982      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/40      1.92G      1.185     0.7295     0.9925         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.9it/s 19.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.4it/s 1.1s0.2s\n",
      "                   all        100        179      0.939      0.954       0.98       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/40      1.92G      1.172     0.6896     0.9906          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.8it/s 19.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 7.5it/s 1.2s0.1s\n",
      "                   all        100        179      0.955      0.954      0.983      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/40      1.92G      1.155     0.6788     0.9972          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.2it/s 18.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 6.5it/s 1.4s0.2s\n",
      "                   all        100        179      0.952      0.961      0.988      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/40      1.92G      1.145     0.6722     0.9798          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.6it/s 20.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.2it/s 1.1s0.2s\n",
      "                   all        100        179      0.961       0.96      0.985      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/40      1.92G      1.147     0.6795      0.986          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.2it/s 16.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.2it/s 1.1s0.1s\n",
      "                   all        100        179       0.94      0.967      0.983      0.668\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/40      1.92G      1.122     0.6827     0.9709          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.1it/s 18.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.0it/s 1.0s0.1s\n",
      "                   all        100        179      0.955      0.958      0.985      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/40      1.92G      1.124      0.654     0.9933          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.4it/s 16.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.4it/s 1.0s0.1s\n",
      "                   all        100        179       0.97      0.939      0.982      0.702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/40      1.92G      1.146     0.6512     0.9817          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.9it/s 19.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 7.0it/s 1.3s0.2s\n",
      "                   all        100        179      0.969      0.944      0.981      0.671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/40      1.92G      1.076     0.6168     0.9533          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.6it/s 20.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 10.3it/s 0.9s.1s\n",
      "                   all        100        179      0.966      0.963      0.986      0.669\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/40      1.92G      1.063     0.5952     0.9849          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.1it/s 21.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 6.9it/s 1.3s0.1s\n",
      "                   all        100        179       0.96       0.95      0.983       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/40      1.92G      1.056      0.592      0.965          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.9it/s 19.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.9it/s 1.0s0.1s\n",
      "                   all        100        179      0.954      0.972       0.99       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/40      1.92G      1.048     0.5851     0.9771          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.1it/s 16.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.0it/s 1.0s0.1s\n",
      "                   all        100        179      0.954       0.95      0.988      0.687\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/40      1.92G       1.02      0.566     0.9659          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.9it/s 19.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.1it/s 1.1s0.2s\n",
      "                   all        100        179      0.977      0.932      0.985      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/40      1.92G      1.019     0.5623     0.9664          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.8it/s 19.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 7.6it/s 1.2s0.2s\n",
      "                   all        100        179      0.981      0.939      0.987      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/40      1.92G          1     0.5612     0.9629          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.4it/s 16.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.9it/s 1.0s0.1s\n",
      "                   all        100        179      0.967      0.966      0.989      0.668\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/40      1.92G     0.9791     0.5513     0.9504          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 6.7it/s 20.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.1it/s 1.1s0.1s\n",
      "                   all        100        179      0.961      0.961      0.987      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/40      1.92G     0.9753     0.5365     0.9465          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.7it/s 17.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 8.6it/s 1.0s0.1s\n",
      "                   all        100        179      0.976       0.95      0.988      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/40      1.92G     0.9341     0.5102     0.9268          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 7.2it/s 18.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.3it/s 1.0s0.1s\n",
      "                   all        100        179      0.972      0.961      0.988      0.706\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/40      1.92G     0.9691     0.5201     0.9441          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 134/134 8.7it/s 15.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 9.8it/s 0.9s0.1s\n",
      "                   all        100        179      0.969      0.961      0.988      0.691\n",
      "\n",
      "40 epochs completed in 0.220 hours.\n",
      "Optimizer stripped from /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2/weights/best.pt...\n",
      "Ultralytics 8.3.222 üöÄ Python-3.10.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 4.4it/s 2.0s0.1s\n",
      "                   all        100        179      0.961      0.961      0.987      0.707\n",
      "Speed: 0.5ms preprocess, 3.8ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/lp_detection_fine_tune_v2\u001b[0m\n",
      "Training complete. Results saved in runs/detect/lp_detection_v1\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "DATA_YAML_PATH = '../data.yaml'\n",
    "\n",
    "target_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"YOLO target device:\", target_device)\n",
    "\n",
    "# Load a pre-trained YOLOv8-nano model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "model.model.to(target_device) \n",
    "\n",
    "# 3. Verify the change (using the reliable check)\n",
    "first_param_device = next(model.model.parameters()).device\n",
    "\n",
    "print(\"‚úÖ Model device (PyTorch check):\", first_param_device)\n",
    "\n",
    "print(\"Starting YOLOv8 training...\")\n",
    "results = model.train(\n",
    "    data=DATA_YAML_PATH,     # Path to the data configuration file\n",
    "    epochs=40,              # Number of epochs (adjust as needed)\n",
    "    imgsz=640,               # Input image size (standard for YOLO)\n",
    "    batch=6,                # Batch size (reduce if you run out of GPU memory)\n",
    "    name='lp_detection_fine_tune_v2',  # Name for the results folder in 'runs/detect\n",
    "    # Optional: use the 'freeze' argument if you want to freeze the backbone \n",
    "    amp=True,\n",
    "    lr0=1e-3\n",
    ")\n",
    "\n",
    "print(\"Training complete. Results saved in runs/detect/lp_detection_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874142b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.222 üöÄ Python-3.10.13 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 1.6¬±0.2 ms, read: 119.7¬±15.2 MB/s, size: 1961.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/data/raw/Indonesian License Plate Dataset/labels/val.cache... 100 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100/100 164.6Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 1.6it/s 4.3s0.3ss\n",
      "                   all        100        179      0.972      0.954      0.988      0.655\n",
      "Speed: 4.7ms preprocess, 6.9ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/d/Uni/Semester 5/Computer Vision/Plate-Recognition/notebooks/runs/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
